 # Hi there! ğŸ‘‹ I'm Suprathika V

### Engineer | Cloud | AI/ML | Curious person

---

ğŸŒŸ Welcome to my GitHub portfolio! Iâ€™m a passionate Engineer with 3+ years of experience building scalable pipelines and cloud architectures. I love turning complex data challenges into elegant, efficient solutions using modern tools and technologies.

---

## About Me

- Currently crafting robust data workflows and real-time streaming systems at Alliant Group  
- Skilled in Python, PySpark, Scala, SQL, and cloud platforms like AWS, Azure & GCP  
- Big fan of clean code, automation, and data-driven decision making  
- Outside work, I enjoy exploring AI chatbots ğŸ¤–, analyzing crime data ğŸ•µï¸â€â™€ï¸, and cooking up new recipes ğŸ³  

---

## What I Build

- Scalable ETL pipelines & data lakes  
- Real-time data streaming & processing systems  
- Predictive models & data dashboards  
- Automated workflows with Airflow & Azure Data Factory  

---

## Tech Stack

**Cloud:** AWS | Azure 
**Big Data:** Spark | Kafka | Hadoop | Databricks  
**Languages:** Python | Scala | Java | SQL | .net |  
**Tools:** Airflow | Jenkins | Docker 
**Visualization & Monitoring:** Power BI | Tableau | Grafana

---

## Featured Projects

### Retailia: AI-powered Chatbot  
*Technologies: Python, NLP, Llama3, RAG, Langchain, Langraph, Agentic Retrieval Augmentation Generation*  
Built an AI chatbot for retail leveraging Llama 3 and Agentic Retrieval Augmentation Generation (RAG), automating 65% of routine queries (order tracking, returns) via real-time SQL DB lookups and FAISS vector search across 10K+ documentation pages, reducing response times by 40%. Python, SQL, Llama 3.1, RAG, Langchain, Langraph.

### [Healthcare Data Pipeline]  
*Technologies: Azure Data Factory, Databricks, Delta Lake, SQL Database*  
Designed and deployed an end-to-end Azure data pipeline using Data Factory, ADLS Gen2, Databricks, and SQL Database. Automated ETL workflows, implemented multi-zone data lake architecture, ensured data governance with Unity Catalog, Azure Key Vault for access control, optimized performance with parallel processing and incremental loads.

### [Neighborhood Theft Analysis] 
*Technologies: OpenRefine, GCP, GCS, Dataproc, Hadoop, BigQuery, Hive SQL, Spark SQl*  
Processed 15+ unstructured crime reports (PDFs/CSV) using OpenRefine, identifying 12 theft patterns (23% weekend spikes) from public datasets; Engineered a data pipeline using GCP (Dataproc, Hadoop), created tables using BigQuery, conducted advanced analysis with Hive and Spark, uncovering time-based crime patterns and insights.  


---

## Let's Connect!

ğŸ“§ suprathika.v@gmail.com  
ğŸ”— [LinkedIn](https://linkedin.com/in/suprathika-v)  
ğŸŒ Denton, TX  

---

Thanks for visiting! Feel free to explore my repos and reach out if you want to collaborate or chat about data engineering and cloud tech. ğŸš€

â­ *Always curious. Always learning.* 
